diff --git a/pipeline/preprocessing.py b/pipeline/preprocessing.py
index 714d325..0490697 100644
--- a/pipeline/preprocessing.py
+++ b/pipeline/preprocessing.py
@@ -81,6 +81,10 @@ except Exception as e:
                         "--is_finished",
                         type=str,
                         help="Is this a continuation of preempted instance?")
+    parser.add_argument("-r",
+                        "--resuming",
+                        type=str,
+                        help="Is this a continuation of preempted instance?")
     args = parser.parse_args()
     if args.stage != None:
         arg_parse_stage = 1
@@ -155,10 +159,6 @@ minimum_return = eval(wandb.config['params']['minimum_return']['value'])
 vertical_barrier_seconds = eval(
     wandb.config['params']['vertical_barrier_seconds']['value'])
 
-# Parameters
-parameters = dict()
-wandb.config['params']['head'][
-    'value'] = 1000  # take only first x number of rows 0 means of
 volume_max = (
     minimum_return + wandb.config['params']['vol_max_modifier']['value']
 )  # The higher this is the more an increase in volatility requries an increase
@@ -390,8 +390,8 @@ if regenerate_features_and_labels == True:
         num_threads=cpus * 2,
         vertical_barrier_times=vertical_barrier_timestamps,
         side_prediction=side,
-        split_by=
-        100  # maybe we want this as large as we can while still fitting in ram
+        split_by=wandb.config['params']['split_by']
+        ['value']  # maybe we want this as large as we can while still fitting in ram
     )
 
     end = time.time()
@@ -497,15 +497,15 @@ if stage == 1:
     end_time = time.time()
     print(end_time - start_time)
 
-    # ### FOR HIGHWAY RNN
-    # X = np.asarray(volumes.loc[labels.index, :])
+    ### FOR HIGHWAY RNN
+    X = np.asarray(volumes.loc[labels.index, :])
 
-    # h5f = h5py.File(path_adjust + "data/preprocessed/" + parameter_string + ".h5", "w")
-    # h5f.create_dataset("X", data=X)
-    # h5f.create_dataset("y", data=y)
-    # h5f.close()
+    h5f = h5py.File(path_adjust + "data/preprocessed/" + parameter_string + "_gam_rhn.h5", "w")
+    h5f.create_dataset("X", data=X)
+    h5f.create_dataset("y", data=y)
+    h5f.close()
 
-    # X = []
+    X = []
 
     start_time = time.time()
 
@@ -600,7 +600,7 @@ if stage == 1:
     print("Make input features from orderbook data started")
     start_time = time.time()
 
-    # MAKE WINDOW FROM INPUTS
+    # Make input features from orderbook data
     input_features_train = make_input_features_from_orderbook_data(
         volumes_for_all_labels_train)
 
Submodule third_party_libraries/TABL contains modified content
diff --git a/third_party_libraries/TABL/__pycache__/Layers.cpython-37.pyc b/third_party_libraries/TABL/__pycache__/Layers.cpython-37.pyc
deleted file mode 100644
index ff0a753..0000000
Binary files a/third_party_libraries/TABL/__pycache__/Layers.cpython-37.pyc and /dev/null differ
diff --git a/third_party_libraries/TABL/__pycache__/Models.cpython-37.pyc b/third_party_libraries/TABL/__pycache__/Models.cpython-37.pyc
deleted file mode 100644
index a57f1ba..0000000
Binary files a/third_party_libraries/TABL/__pycache__/Models.cpython-37.pyc and /dev/null differ
Submodule third_party_libraries/gam_rhn contains modified content
diff --git a/third_party_libraries/gam_rhn/95-FI2010/fi_core.py b/third_party_libraries/gam_rhn/95-FI2010/fi_core.py
index 4a37d36..7996516 100644
--- a/third_party_libraries/gam_rhn/95-FI2010/fi_core.py
+++ b/third_party_libraries/gam_rhn/95-FI2010/fi_core.py
@@ -8,7 +8,8 @@ for _ in range(DIR_DEPTH + 1):
     ROOT = os.path.dirname(ROOT)
     sys.path.insert(0, ROOT)
 import numpy as np
-import tensorflow as tf
+import tensorflow.compat.v1 as tf
+tf.disable_v2_behavior()
 from tframe import console, SaveMode
 from tframe import Classifier
 from tframe.trainers import SmartTrainerHub as Config
@@ -89,10 +90,13 @@ def activate():
     # Calculate class weights
     if th.class_weights is None and th.loss_string == "wce":
         train_targets = train_set.stack.targets.flatten()
-        samples_per_class = [sum(train_targets == c) for c in range(th.num_classes)]
+        samples_per_class = [
+            sum(train_targets == c) for c in range(th.num_classes)
+        ]
         class_weights = min(samples_per_class) / np.array(samples_per_class)
         th.class_weights = class_weights
-        console.show_status("Class weights set to {}".format(th.class_weights), "++")
+        console.show_status("Class weights set to {}".format(th.class_weights),
+                            "++")
 
     # Set input shape according to th.max_level and th.volume_only
     du.FI2010.set_input_shape()
@@ -102,6 +106,9 @@ def activate():
     model = th.model(th)
     assert isinstance(model, Classifier)
 
+    import pdb
+    pdb.set_trace()
+
     # Train or evaluate
     if th.train:
         model.train(
diff --git a/third_party_libraries/gam_rhn/95-FI2010/t95_bl_gam_rhn.py b/third_party_libraries/gam_rhn/95-FI2010/t95_bl_gam_rhn.py
index 4e6678f..bd2f165 100644
--- a/third_party_libraries/gam_rhn/95-FI2010/t95_bl_gam_rhn.py
+++ b/third_party_libraries/gam_rhn/95-FI2010/t95_bl_gam_rhn.py
@@ -1,4 +1,5 @@
-import tensorflow as tf
+import tensorflow.compat.v1 as tf
+tf.disable_v2_behavior()
 import fi_core as core
 import fi_mu as m
 from tframe import console
@@ -41,8 +42,7 @@ def model(th):
             kernel=th.hyper_kernel,
             gam_dropout=th.gam_dropout,
             rhn_dropout=th.rhn_dropout,
-        )
-    )
+        ))
     return m.typical(th, layers)
 
 
@@ -121,4 +121,3 @@ def main(_):
 
 if __name__ == "__main__":
     tf.app.run()
-
Submodule tframe contains modified content
Submodule tframe 4c4289d..37c9f0b:
diff --git a/third_party_libraries/gam_rhn/tframe/configs/flag.py b/third_party_libraries/gam_rhn/tframe/configs/flag.py
index 32723d2..e4be7a6 100644
--- a/third_party_libraries/gam_rhn/tframe/configs/flag.py
+++ b/third_party_libraries/gam_rhn/tframe/configs/flag.py
@@ -3,18 +3,24 @@ from __future__ import division
 from __future__ import print_function
 
 import re
-import tensorflow as tf
+import tensorflow.compat.v1 as tf
+tf.disable_v2_behavior()
 from tframe.enums import EnumPro
 
 flags = tf.app.flags
 
-
 # TODO: Value set to Flag should be checked
 
+
 class Flag(object):
-  def __init__(self, default_value, description, register=None, name=None,
-               is_key=False, **kwargs):
-    """
+    def __init__(self,
+                 default_value,
+                 description,
+                 register=None,
+                 name=None,
+                 is_key=False,
+                 **kwargs):
+        """
     ... another way to design this class is to let name attribute be assigned
     when registered, but we need to allow FLAGS names such as 'job-dir' to be
     legal. In this perspective, this design is better.
@@ -26,143 +32,163 @@ class Flag(object):
                     (3) None: show if has been modified
     :param register: if is None, this flag can not be passed via tf FLAGS
     """
-    self.name = name
-    self._default_value = default_value
-    self._description = description
-    self._register = register
-    self._is_key = is_key
-    self._kwargs = kwargs
-
-    self._value = default_value
-    self._frozen = False
-
-  # region : Properties
-
-  @property
-  def ready_to_be_key(self):
-    return self._is_key is None
-
-  @property
-  def is_key(self):
-    if self._is_key is False: return False
-    if not self.should_register: return self._is_key is True
-    assert hasattr(flags.FLAGS, self.name)
-    return self._is_key is True or getattr(flags.FLAGS, self.name) is not None
-
-  @property
-  def frozen(self):
-    return self._frozen
-
-  @property
-  def value(self):
-    # If not registered to tf.app.flags or has been frozen
-    if self._register is None or self._frozen: return self._value
-
-    assert hasattr(flags.FLAGS, self.name)
-    f_value = getattr(flags.FLAGS, self.name)
-    # Configs defined via tensorflow FLAGS have priority over any other way
-    if f_value is None: return self._value
-    # If self is en enum Flag, then f_value must be a string in
-    # .. self.enum_class.value_list(), so we need to get its member
-    if self.is_enum: f_value = self.enum_class.get_member(f_value)
-    if self.frozen and self._value != f_value:
-      raise AssertionError(
-        "!! Invalid tensorflow FLAGS value {0}={1} 'cause {0} has been "
-        "frozen to {2}".format(self.name, f_value, self._value))
-    return f_value
-
-  @property
-  def should_register(self):
-    return self._register is not None
-
-  @property
-  def enum_class(self):
-    cls = self._kwargs.get('enum_class', None)
-    if cls is None or not issubclass(cls, EnumPro): return None
-    return cls
-
-  @property
-  def is_enum(self):
-    return self.enum_class is not None and self._register is flags.DEFINE_enum
-
-  # endregion : Properties
-
-  # region : Class Methods
-
-  @classmethod
-  def whatever(cls, default_value, description, is_key=False):
-    return Flag(default_value, description, is_key=is_key)
-
-  @classmethod
-  def string(cls, default_value, description, name=None, is_key=False):
-    return Flag(default_value, description, flags.DEFINE_string, name,
-                is_key=is_key)
-
-  @classmethod
-  def boolean(cls, default_value, description, name=None, is_key=False):
-    return Flag(default_value, description, flags.DEFINE_boolean, name,
-                is_key=is_key)
-
-  @classmethod
-  def integer(cls, default_value, description, name=None, is_key=False):
-    return Flag(default_value, description, flags.DEFINE_integer, name,
-                is_key=is_key)
-
-  @classmethod
-  def float(cls, default_value, description, name=None, is_key=False):
-    return Flag(default_value, description, flags.DEFINE_float, name,
-                is_key=is_key)
-
-  @classmethod
-  def list(cls, default_value, description, name=None):
-    return Flag(default_value, description, flags.DEFINE_list, name)
-
-  @classmethod
-  def enum(cls, default_value, enum_class, description, name=None,
-           is_key=False):
-    assert issubclass(enum_class, EnumPro)
-    return Flag(default_value, description, flags.DEFINE_enum, name,
-                enum_class=enum_class, is_key=is_key)
-
-  # endregion : Class Methods
-
-  # region : Public Methods
-
-  def register(self, name):
-    # If name is not specified during construction, use flag's attribute name
-    # .. in Config
-    if self.name is None: self.name = name
-    if self._register is None or self.name in list(flags.FLAGS): return
-    # Register enum flag
-    if self.is_enum:
-      flags.DEFINE_enum(
-        self.name, None, self.enum_class.value_list(), self._description)
-      return
-    # Register other flag
-    assert self._register is not flags.DEFINE_enum
-    self._register(self.name, None, self._description)
-
-  def new_value(self, value):
-    flg = Flag(self._default_value, self._description, self._register,
-               self.name, **self._kwargs)
-    flg._value = value
-    return flg
-
-  def freeze(self, value):
-    self._value = value
-    self._frozen = True
-
-  # endregion : Public Methods
-
-  # region : Private Methods
-
-  @staticmethod
-  def parse_comma(arg, dtype=str):
-    r = re.fullmatch(r'([\-\d.,]+)', arg)
-    if r is None: raise AssertionError(
-      'Can not parse argument `{}`'.format(arg))
-    val_list = re.split(r'[,]', r.group())
-    return [dtype(v) for v in val_list]
-
-  # endregion : Private Methods
-
+        self.name = name
+        self._default_value = default_value
+        self._description = description
+        self._register = register
+        self._is_key = is_key
+        self._kwargs = kwargs
+
+        self._value = default_value
+        self._frozen = False
+
+    # region : Properties
+
+    @property
+    def ready_to_be_key(self):
+        return self._is_key is None
+
+    @property
+    def is_key(self):
+        if self._is_key is False: return False
+        if not self.should_register: return self._is_key is True
+        assert hasattr(flags.FLAGS, self.name)
+        return self._is_key is True or getattr(flags.FLAGS,
+                                               self.name) is not None
+
+    @property
+    def frozen(self):
+        return self._frozen
+
+    @property
+    def value(self):
+        # If not registered to tf.app.flags or has been frozen
+        if self._register is None or self._frozen: return self._value
+
+        assert hasattr(flags.FLAGS, self.name)
+        f_value = getattr(flags.FLAGS, self.name)
+        # Configs defined via tensorflow FLAGS have priority over any other way
+        if f_value is None: return self._value
+        # If self is en enum Flag, then f_value must be a string in
+        # .. self.enum_class.value_list(), so we need to get its member
+        if self.is_enum: f_value = self.enum_class.get_member(f_value)
+        if self.frozen and self._value != f_value:
+            raise AssertionError(
+                "!! Invalid tensorflow FLAGS value {0}={1} 'cause {0} has been "
+                "frozen to {2}".format(self.name, f_value, self._value))
+        return f_value
+
+    @property
+    def should_register(self):
+        return self._register is not None
+
+    @property
+    def enum_class(self):
+        cls = self._kwargs.get('enum_class', None)
+        if cls is None or not issubclass(cls, EnumPro): return None
+        return cls
+
+    @property
+    def is_enum(self):
+        return self.enum_class is not None and self._register is flags.DEFINE_enum
+
+    # endregion : Properties
+
+    # region : Class Methods
+
+    @classmethod
+    def whatever(cls, default_value, description, is_key=False):
+        return Flag(default_value, description, is_key=is_key)
+
+    @classmethod
+    def string(cls, default_value, description, name=None, is_key=False):
+        return Flag(default_value,
+                    description,
+                    flags.DEFINE_string,
+                    name,
+                    is_key=is_key)
+
+    @classmethod
+    def boolean(cls, default_value, description, name=None, is_key=False):
+        return Flag(default_value,
+                    description,
+                    flags.DEFINE_boolean,
+                    name,
+                    is_key=is_key)
+
+    @classmethod
+    def integer(cls, default_value, description, name=None, is_key=False):
+        return Flag(default_value,
+                    description,
+                    flags.DEFINE_integer,
+                    name,
+                    is_key=is_key)
+
+    @classmethod
+    def float(cls, default_value, description, name=None, is_key=False):
+        return Flag(default_value,
+                    description,
+                    flags.DEFINE_float,
+                    name,
+                    is_key=is_key)
+
+    @classmethod
+    def list(cls, default_value, description, name=None):
+        return Flag(default_value, description, flags.DEFINE_list, name)
+
+    @classmethod
+    def enum(cls,
+             default_value,
+             enum_class,
+             description,
+             name=None,
+             is_key=False):
+        assert issubclass(enum_class, EnumPro)
+        return Flag(default_value,
+                    description,
+                    flags.DEFINE_enum,
+                    name,
+                    enum_class=enum_class,
+                    is_key=is_key)
+
+    # endregion : Class Methods
+
+    # region : Public Methods
+
+    def register(self, name):
+        # If name is not specified during construction, use flag's attribute name
+        # .. in Config
+        if self.name is None: self.name = name
+        if self._register is None or self.name in list(flags.FLAGS): return
+        # Register enum flag
+        if self.is_enum:
+            flags.DEFINE_enum(self.name, None, self.enum_class.value_list(),
+                              self._description)
+            return
+        # Register other flag
+        assert self._register is not flags.DEFINE_enum
+        self._register(self.name, None, self._description)
+
+    def new_value(self, value):
+        flg = Flag(self._default_value, self._description, self._register,
+                   self.name, **self._kwargs)
+        flg._value = value
+        return flg
+
+    def freeze(self, value):
+        self._value = value
+        self._frozen = True
+
+    # endregion : Public Methods
+
+    # region : Private Methods
+
+    @staticmethod
+    def parse_comma(arg, dtype=str):
+        r = re.fullmatch(r'([\-\d.,]+)', arg)
+        if r is None:
+            raise AssertionError('Can not parse argument `{}`'.format(arg))
+        val_list = re.split(r'[,]', r.group())
+        return [dtype(v) for v in val_list]
+
+    # endregion : Private Methods
diff --git a/third_party_libraries/gam_rhn/tframe/examples/00-MNIST/mn_core.py b/third_party_libraries/gam_rhn/tframe/examples/00-MNIST/mn_core.py
index d1fabef..a4adcd8 100644
--- a/third_party_libraries/gam_rhn/tframe/examples/00-MNIST/mn_core.py
+++ b/third_party_libraries/gam_rhn/tframe/examples/00-MNIST/mn_core.py
@@ -9,7 +9,9 @@ for _ in range(DIR_DEPTH + 1):
 from tframe import console, SaveMode
 from tframe.trainers import SmartTrainerHub
 from tframe import Classifier
+from tframe import monitor
 
+import mn_ad as ad
 import mn_du as du
 
 
@@ -61,6 +63,10 @@ th.evaluate_test_set = True
 
 
 def activate(export_false=False):
+  # Register activation filter
+  if th.export_activations:
+    monitor.register_activation_filter(ad.act_type_ii_filter)
+
   # Load data
   train_set, val_set, test_set = du.load_data(th.data_dir)
 
diff --git a/third_party_libraries/gam_rhn/tframe/examples/00-MNIST/mn_mu.py b/third_party_libraries/gam_rhn/tframe/examples/00-MNIST/mn_mu.py
index ab29462..788e663 100644
--- a/third_party_libraries/gam_rhn/tframe/examples/00-MNIST/mn_mu.py
+++ b/third_party_libraries/gam_rhn/tframe/examples/00-MNIST/mn_mu.py
@@ -19,7 +19,7 @@ def get_container(th, flatten=False):
     model.add(Flatten())
     # Register extractor and researcher
     model.register_extractor(mn_du.MNIST.connection_heat_map_extractor)
-    monitor.register_researcher(mn_du.MNIST.flatten_researcher)
+    monitor.register_grad_researcher(mn_du.MNIST.flatten_researcher)
   return model
 
 
diff --git a/third_party_libraries/gam_rhn/tframe/examples/01-CIFAR10/cf10_mu.py b/third_party_libraries/gam_rhn/tframe/examples/01-CIFAR10/cf10_mu.py
index 49868ae..ea35a1b 100644
--- a/third_party_libraries/gam_rhn/tframe/examples/01-CIFAR10/cf10_mu.py
+++ b/third_party_libraries/gam_rhn/tframe/examples/01-CIFAR10/cf10_mu.py
@@ -20,7 +20,7 @@ def get_container(th, flatten=False):
   assert isinstance(th, Config)
   model = Classifier(mark=th.mark)
   model.add(Input(sample_shape=th.input_shape))
-  if th.centralize_data: model.add(Normalize(mu=th.data_mean))
+  if th.centralize_data: model.add(Normalize(mu=th.data_mean, sigma=255.))
   if flatten: model.add(Flatten())
   return model
 
@@ -32,7 +32,7 @@ def finalize(th, model):
   # model.add(Dense(num_neurons=th.num_classes))
   model.add(Activation('softmax'))
   # Build model
-  model.build(metric=['loss', 'accuracy'], batch_metric='accuracy',
+  model.build(metric=['accuracy', 'loss'], batch_metric='accuracy',
               eval_metric='accuracy')
   return model
 
@@ -61,7 +61,7 @@ def multinput(th):
   model.add(Linear(output_dim=th.num_classes))
 
   # Build model
-  model.build(metric=['loss', 'accuracy'], batch_metric='accuracy',
+  model.build(metric=['accuracy', 'loss'], batch_metric='accuracy',
               eval_metric='accuracy')
 
   return model
diff --git a/third_party_libraries/gam_rhn/tframe/examples/view_notes.py b/third_party_libraries/gam_rhn/tframe/examples/view_notes.py
index 1e7ac4f..bdfa201 100644
--- a/third_party_libraries/gam_rhn/tframe/examples/view_notes.py
+++ b/third_party_libraries/gam_rhn/tframe/examples/view_notes.py
@@ -8,6 +8,7 @@ for _ in range(DIR_DEPTH + 1):
 from tframe.utils.summary_viewer.main_frame import SummaryViewer
 from tframe import local
 from tframe.utils.tensor_viewer.plugins import lottery
+from tframe.utils.tensor_viewer.plugins import activation_sparsity
 
 
 default_inactive_flags = (
@@ -58,7 +59,8 @@ while True:
       default_inactive_criteria=default_inactive_criteria,
       flags_to_ignore=flags_to_ignore,
     )
-    viewer.register_plugin(lottery.plugin)
+    # viewer.register_plugin(lottery.plugin)
+    viewer.register_plugin(activation_sparsity.plugin)
     viewer.show()
 
   except Exception as e:
diff --git a/third_party_libraries/gam_rhn/tframe/layers/sparse/sparse_sog_n.py b/third_party_libraries/gam_rhn/tframe/layers/sparse/sparse_sog_n.py
index 1477613..89e81ff 100644
--- a/third_party_libraries/gam_rhn/tframe/layers/sparse/sparse_sog_n.py
+++ b/third_party_libraries/gam_rhn/tframe/layers/sparse/sparse_sog_n.py
@@ -4,6 +4,7 @@ from __future__ import print_function
 
 import tensorflow as tf
 
+from tframe import context
 from tframe import checker
 from tframe import hub as th
 from tframe.activations import sog
@@ -71,6 +72,9 @@ class SparseSOG(HyperBase):
       net_gate = self.dense_v2(self._num_neurons, 'seed', head)
     gate = sog(net_gate, self._group_size)
 
+    # Export gates if necessary
+    if th.export_gates: context.add_tensor_to_export('sog_gate', gate)
+
     # Apply gate
     y = tf.multiply(y_bar, gate, 'y')
     # ~
diff --git a/third_party_libraries/gam_rhn/tframe/utils/janitor.py b/third_party_libraries/gam_rhn/tframe/utils/janitor.py
index a8d33c7..8f7e6f3 100644
--- a/third_party_libraries/gam_rhn/tframe/utils/janitor.py
+++ b/third_party_libraries/gam_rhn/tframe/utils/janitor.py
@@ -5,6 +5,16 @@ from __future__ import print_function
 import numpy as np
 
 
+def wrap(obj, obj_type=None, wrap_as=list):
+  """Wrap obj into list."""
+  assert wrap_as in (list, tuple)
+  if not isinstance(obj, wrap_as): obj = wrap_as([obj])
+  if obj_type is not None:
+    from tframe import checker
+    obj = checker.check_type_v2(obj, obj_type)
+  return obj
+
+
 def recover_seq_set_outputs(outputs, seq_set):
   """Outputs of tframe batch evaluation are messed up.
      This method will help.
diff --git a/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/main_frame.py b/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/main_frame.py
index 1c1de02..354eb63 100644
--- a/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/main_frame.py
+++ b/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/main_frame.py
@@ -9,6 +9,7 @@ try:
   from PIL import Image as Image_
   from PIL import ImageTk
 
+  from tframe.utils import janitor
   from tframe.utils.note import Note
   from tframe.utils.tensor_viewer import key_events
   from tframe.utils.tensor_viewer.context import Context
@@ -44,7 +45,7 @@ class TensorViewer(Viewer):
     self._global_refresh()
 
     # Set plugin (beta) (This line should be put before set_note)
-    self._plugins = kwargs.get('plugins', [])
+    self._plugins = janitor.wrap(kwargs.get('plugins', []))
 
     # If note or note_path is provided, try to load it
     if note is not None or note_path is not None:
diff --git a/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/plugin.py b/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/plugin.py
index 7828e00..a83eb0e 100644
--- a/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/plugin.py
+++ b/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/plugin.py
@@ -2,6 +2,7 @@ from __future__ import absolute_import
 from __future__ import division
 from __future__ import print_function
 
+import inspect
 from collections import OrderedDict
 
 
@@ -24,3 +25,27 @@ class VariableWithView(object):
     self._view = view
 
   def display(self, vv): self._view(vv, self._value_list)
+
+
+def recursively_modify(method, v_dict, level=0, verbose=True):
+  """This method recursively modifies v_dict with a provided 'method'.
+     'method' accepts keys and values(list of numpy arrays) and returns
+     modified values (which can be a tframe.VariableViewer).
+     Sometimes method should contain logic to determine whether the input values
+     should be modified.
+  """
+  # Sanity check
+  assert callable(method) and isinstance(v_dict, dict)
+  assert inspect.getfullargspec(method).args == ['key', 'value']
+  if len(v_dict) == 0: return
+
+  # If values in v_dict are dictionaries,  recursively modify each of them
+  if isinstance(list(v_dict.values())[0], dict):
+    for e_key, e_dict in v_dict.items():
+      assert isinstance(e_dict, dict)
+      if verbose: print('*> modifying dict {} ...'.format(e_key))
+      recursively_modify(method, e_dict, level=level+1, verbose=verbose)
+    return
+
+  # At this point, values in v_dict must be lists of numpy arrays
+  for key in v_dict.keys(): v_dict[key] = method(key, v_dict[key])
diff --git a/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/plugins/activation_sparsity.py b/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/plugins/activation_sparsity.py
new file mode 100644
index 0000000..437cf08
--- /dev/null
+++ b/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/plugins/activation_sparsity.py
@@ -0,0 +1,67 @@
+import re
+from collections import OrderedDict
+
+import numpy as np
+
+import matplotlib.pyplot as plt
+
+from tframe import checker
+from tframe.utils.tensor_viewer.plugin import Plugin, VariableWithView
+from tframe.utils.tensor_viewer.plugin import recursively_modify
+
+from .plotter.histogram import histogram
+from .plotter.heatmap1d import linear_heatmap
+from .plotter.heatmap1dto2d import heatmap2d
+
+
+def view(self, array_list):
+  from tframe.utils.tensor_viewer.variable_viewer import VariableViewer
+  assert isinstance(array_list, list) and isinstance(self, VariableViewer)
+
+  # Handle things happens in VariableView.refresh method
+
+  # Create subplots if not exists
+  if not hasattr(self, 'sub211'):
+    self.sub211 = self.figure.add_subplot(211, autoscale_on=True)
+  if not hasattr(self, 'sub212'):
+    self.sub212 = self.figure.add_subplot(212, autoscale_on=True)
+  # Clear subplots
+  self.sub211.cla()
+  self.sub212.cla()
+  # Hide subplot
+  self.subplot.set_axis_off()
+
+  # Hide ax2
+  self.set_ax2_invisible()
+
+  # Plot histogram
+
+  # Get range
+  a_range = [np.min(array_list), np.max(array_list)]
+  # Get activation
+  activation = array_list[self.index].flatten()
+  title = 'Activation Distribution'
+  histogram(self.sub211, activation, val_range=a_range, title=title)
+
+  # Plot heat-map
+  heatmap2d(self.sub212, activation, folds=5)
+
+  # Tight layout
+  self.figure.tight_layout()
+
+
+def method(key, value):
+  assert isinstance(key, str)
+  if 'sog_gate' not in key: return value
+  checker.check_type_v2(value, np.ndarray)
+  # Make sure activation is 1-D array
+  assert len(value[0].shape) == 1
+  return VariableWithView(value, view)
+
+
+def modifier(v_dict):
+  assert isinstance(v_dict, OrderedDict)
+  recursively_modify(method, v_dict, verbose=True)
+
+
+plugin = Plugin(dict_modifier=modifier)
diff --git a/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/plugins/plotter/__init__.py b/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/plugins/plotter/__init__.py
new file mode 100644
index 0000000..e69de29
diff --git a/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/plugins/plotter/heatmap1d.py b/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/plugins/plotter/heatmap1d.py
new file mode 100644
index 0000000..cc7ddaa
--- /dev/null
+++ b/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/plugins/plotter/heatmap1d.py
@@ -0,0 +1,28 @@
+import numpy as np
+
+import matplotlib.pyplot as plt
+
+
+def linear_heatmap(
+    subplot, array, title=None, horizontal=True, cmap='bwr', width=2,
+    vmax=1, vmin=-1):
+  assert isinstance(subplot, plt.Axes) and isinstance(array, np.ndarray)
+  assert isinstance(width, int) and width >= 1
+
+  # Stretch image
+  img = np.stack([array.flatten()] * width, axis=0 if horizontal else 1)
+
+  # Plot image
+  subplot.imshow(img, cmap=cmap, interpolation='none', vmin=vmin, vmax=vmax)
+
+  # Hide y axis
+  subplot.yaxis.set_ticks([])
+
+  # Set grid off
+  subplot.axis('off')
+
+  # Set title if provided
+  if isinstance(title, str): subplot.set_title(title)
+
+
+
diff --git a/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/plugins/plotter/heatmap1dto2d.py b/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/plugins/plotter/heatmap1dto2d.py
new file mode 100644
index 0000000..dc0a01c
--- /dev/null
+++ b/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/plugins/plotter/heatmap1dto2d.py
@@ -0,0 +1,54 @@
+import numpy as np
+
+import matplotlib.pyplot as plt
+
+
+def heatmap2d(subplot, array, title=None, folds=5, v_range=None,
+              min_color=(1., 1., 1.), max_color=(1., 0., 0.), grey=0.7):
+  """
+  :param array: numpy array
+  :param folds: height of the image to plot
+  :param v_range: value range, a tuple/list of 2 float number. None by default
+  :param min_color: color of pixel with min value, a tuple/list of 3 float
+                     numbers between 0. and 1.
+  :param max_color: color of pixel with max value, a tuple/list of 3 float
+                     number between 0. and 1.
+  """
+  # Check subplot and array
+  assert isinstance(subplot, plt.Axes) and isinstance(array, np.ndarray)
+  assert isinstance(folds, int) and folds > 0
+  # Check v_range
+  v_min, v_max = v_range if v_range else (min(array), max(array))
+  assert v_max - v_min > 0.
+
+  # Create a grey line
+  size = array.size
+  width = int(np.ceil(size / folds))
+  max_color, min_color = [
+    np.reshape(v, newshape=[1, 3]) for v in (max_color, min_color)]
+  line = np.ones(shape=[width * folds, 3]) * grey
+
+  # Map array into pixels with color and put them into the line
+  values = np.maximum(0, array - v_min) / (v_max - v_min)
+  values = np.stack([values] * 3, axis=1)
+  values = values * (max_color - min_color) + min_color
+  line[:size] = values
+
+  # Fold line to image
+  img = np.reshape(line, newshape=(folds, width, 3))
+
+  # Plot image
+  subplot.imshow(img, interpolation='none')
+
+  # Hide y axis
+  subplot.yaxis.set_ticks([])
+
+  # Set grid off
+  subplot.axis('off')
+
+  # Set title if provided
+  if isinstance(title, str): subplot.set_title(title)
+
+
+
+
diff --git a/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/plugins/plotter/histogram.py b/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/plugins/plotter/histogram.py
new file mode 100644
index 0000000..69fbffd
--- /dev/null
+++ b/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/plugins/plotter/histogram.py
@@ -0,0 +1,35 @@
+import numpy as np
+
+import matplotlib
+import matplotlib.pyplot as plt
+from matplotlib.ticker import FuncFormatter
+
+
+def histogram(
+    subplot, values, val_range=None, title='Distribution', y_lim_pct=0.5):
+
+  assert isinstance(subplot, plt.Axes) and isinstance(values, np.ndarray)
+  # values for 1-D distribution must be flattened
+  if len(values.shape) > 1: values = values.flatten()
+
+  # Plot 1-D histogram
+  subplot.hist(values, bins=50, facecolor='#cccccc', range=val_range)
+  subplot.set_title(title)
+  subplot.set_xlabel('Magnitude')
+  subplot.set_ylabel('Density')
+
+  # ~
+  def to_percent(y, _):
+    usetex = matplotlib.rcParams['text.usetex']
+    pct = y * 100.0 / values.size
+    return '{:.1f}{}'.format(pct, r'$\%$' if usetex else '%')
+  subplot.yaxis.set_major_formatter(FuncFormatter(to_percent))
+
+  subplot.set_aspect('auto')
+  subplot.grid(True)
+
+  subplot.set_ylim([0.0, y_lim_pct * values.size])
+
+
+
+
diff --git a/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/plugins/xwy.py b/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/plugins/plotter/xwy.py
similarity index 100%
rename from utils/tensor_viewer/plugins/xwy.py
rename to utils/tensor_viewer/plugins/plotter/xwy.py
diff --git a/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/plugins/weights_distribution.py b/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/plugins/weights_distribution.py
index 4c52d80..5a9f01e 100644
--- a/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/plugins/weights_distribution.py
+++ b/third_party_libraries/gam_rhn/tframe/utils/tensor_viewer/plugins/weights_distribution.py
@@ -6,6 +6,7 @@ import matplotlib
 from matplotlib.ticker import FuncFormatter
 
 from tframe.utils.tensor_viewer.plugin import Plugin, VariableWithView
+from .plotter import histogram
 
 
 prefix = 'weights_'
@@ -31,27 +32,13 @@ def view(self, weights_list):
   weights = weights_list[self.index]
   assert isinstance(weights, np.ndarray)
   weights = weights.flatten()
-  # Plot
+
+  # Hide ax2
   self.set_ax2_invisible()
 
-  self.subplot.hist(weights, bins=50, facecolor='#cccccc', range=w_range)
-  self.subplot.set_title(
-    'Weights magnitude distribution ({} total)'.format(weights.size))
-  self.subplot.set_xlabel('Magnitude')
-  self.subplot.set_ylabel('Density')
-  # self.subplot.set_xlim(w_range)
-
-  def to_percent(y, _):
-    usetex = matplotlib.rcParams['text.usetex']
-    pct = y * 100.0 / weights.size
-    return '{:.1f}{}'.format(pct, r'$\%$' if usetex else '%')
-  self.subplot.yaxis.set_major_formatter(FuncFormatter(to_percent))
-
-  self.subplot.set_aspect('auto')
-  self.subplot.grid(True)
-
-  # y_lim = self.subplot.get_ylim()
-  # if y_lim[0] > y_lim[1]: self.subplot.set_ylim(y_lim[::-1])
-  self.subplot.set_ylim([0.0, 0.065 * weights.size])
+  # Plot histogram
+  title = 'Weights magnitude distribution ({} total)'.format(weights.size)
+  histogram.histogram(self, weights, val_range=w_range, title=title)
+
 
 plugin = Plugin(dict_modifier=modifier)
diff --git a/yaml/preprocessing.yaml b/yaml/preprocessing.yaml
index 18512e2..91f0191 100644
--- a/yaml/preprocessing.yaml
+++ b/yaml/preprocessing.yaml
@@ -10,13 +10,16 @@ stop_loss_multiplier:
   value: 1
 minimum_return:
   desc: Amount of return chosen to consider it a profitable trade
-  value: 0.001 * 1 / 23
+  value: 0.001 * 1 / 30
 vertical_barrier_seconds:
   desc: Length of the labelling window
   value: round(1 / 2, 3)
 head:
   desc: Take the first n values of dataframes. If it equals zero take the entire df
   value: 1000
+split_by:
+  desc: Number of samples to split get_events function on to avoid maxing out the ram
+  value: 100
 vol_max_modifier: 
   desc: How much extra profit above minimum return required in the face of max volatility
   value: 0.00000002
