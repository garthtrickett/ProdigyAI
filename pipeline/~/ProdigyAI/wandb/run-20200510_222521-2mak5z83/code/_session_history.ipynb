{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 0, 3)"
     ]
    }
   ],
   "source": [
    "print(\"script initiated\")\n",
    "import time\n",
    "very_start = time.time()\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import tables as tb\n",
    "sys.path.append(\"..\")\n",
    "cwd = os.getcwd()\n",
    "from pathlib import Path\n",
    "home = str(Path.home())\n",
    "sys.path.append(home + \"/ProdigyAI\")\n",
    "from multiprocessing import cpu_count\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import numpy as np\n",
    "np.set_printoptions(suppress=True)  # don't use scientific notati\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "# from hanging_threads import start_monitoring\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer, MinMaxScaler, StandardScaler\n",
    "import keras\n",
    "import third_party_libraries.finance_ml\n",
    "import third_party_libraries.hudson_and_thames.mlfinlab as ml\n",
    "import third_party_libraries.hudson_and_thames.mlfinlab.labeling.labeling as labeling\n",
    "import third_party_libraries.hudson_and_thames.mlfinlab.sample_weights.attribution as attribution\n",
    "import third_party_libraries.snippets as snp\n",
    "from third_party_libraries.finance_ml.stats.vol import *\n",
    "\n",
    "from library.core import *\n",
    "# monitoring_thread = start_monitoring(seconds_frozen=360, test_interval=100)\n",
    "# import googlecloudprofiler\n",
    "# try:\n",
    "#     googlecloudprofiler.start(\n",
    "#         service=\"preemp-cpu-big-full-jeff_in-max\",\n",
    "#         # verbose is the logging level. 0-error, 1-warning, 2-info,\n",
    "#         # 3-debug. It defaults to 0 (error) if not set.\n",
    "#         verbose=3,\n",
    "#     )\n",
    "# except (ValueError, NotImplementedError) as exc:\n",
    "#     print(exc)  # Handle errors here\n",
    "\n",
    "arg_parse_stage = None\n",
    "# Sorting out whether we are using the ipython kernel or not\n",
    "\n",
    "try:\n",
    "    get_ipython()\n",
    "    check_if_ipython = True\n",
    "    path_adjust = \"../\"\n",
    "except Exception as e:\n",
    "    check_if_ipython = False\n",
    "    split_cwd = cwd.split(\"/\")\n",
    "    last_string = split_cwd.pop(-1)\n",
    "    cwd = cwd.replace(last_string, \"\")\n",
    "    os.chdir(cwd)\n",
    "    parser = argparse.ArgumentParser(description=\"Preprocessing\")\n",
    "    parser.add_argument(\"-s\",\n",
    "                        \"--stage\",\n",
    "                        type=str,\n",
    "                        help=\"Stage of Preprocesssing\")\n",
    "    parser.add_argument(\"-m\",\n",
    "                        \"--model\",\n",
    "                        type=str,\n",
    "                        help=\"one_model or two_model\")\n",
    "    parser.add_argument(\"-f\",\n",
    "                        \"--is_finished\",\n",
    "                        type=str,\n",
    "                        help=\"Is this a continuation of preempted instance?\")\n",
    "    args = parser.parse_args()\n",
    "    if args.stage != None:\n",
    "        arg_parse_stage = 1\n",
    "        if int(args.stage) == 1:\n",
    "            if os.path.exists(path_adjust + \"temp/data_name_gpu.txt\"):\n",
    "                os.remove(path_adjust + \"temp/data_name_gpu.txt\")\n",
    "                print(\"removed temp/data_name_gpu.txt\")\n",
    "            else:\n",
    "                print(\"The file does not exist\")\n",
    "    if args.model != None:\n",
    "        model = args.model\n",
    "    path_adjust = \"\"\n",
    "\n",
    "if cwd == home + \"/\":\n",
    "    cwd = cwd + \"/ProdigyAI\"\n",
    "    path_adjust = cwd\n",
    "\n",
    "try:\n",
    "    with open(path_adjust + \"temp/data_name_gpu.txt\", \"r\") as text_file:\n",
    "        gpu_file_name = text_file.read()\n",
    "        stage = 2\n",
    "except:\n",
    "    stage = 1\n",
    "\n",
    "side = None\n",
    "\n",
    "with open(path_adjust + \"temp/is_script_finished.txt\", \"w+\") as text_file:\n",
    "    text_file.write(\"start_script_time\" + str(very_start))\n",
    "\n",
    "if arg_parse_stage == 1:\n",
    "    stage = int(args.stage)\n",
    "\n",
    "print(\"the stage\" + str(stage))\n",
    "# Overide model and stage for testing\n",
    "\n",
    "model = \"two_model\"\n",
    "stage = 1\n",
    "print(\"the overidden stage\" + str(stage))\n",
    "\n",
    "if stage == 2:\n",
    "    # size\n",
    "    h5f = h5py.File(\"data/gpu_output/\" + gpu_file_name + \".h5\", \"r\")\n",
    "    X = h5f[\"X\"][:]\n",
    "    P = h5f[\"P\"][:]\n",
    "    sample_weights = h5f[\"sample_weights\"][:]\n",
    "    sampled_idx_epoch = h5f[\"sampled_idx_epoch\"][:]\n",
    "    h5f.close()\n",
    "    data = pq.read_pandas(\"data/gpu_output/\" + gpu_file_name +\n",
    "                          \"_data.parquet\").to_pandas()\n",
    "    X_for_all_labels = data.dropna(subset=[\"bins\"])\n",
    "    sampled_idx = pd.DatetimeIndex(sampled_idx_epoch)\n",
    "    X_for_all_labels[\"predicted_bins\"] = P\n",
    "    side = X_for_all_labels[\"predicted_bins\"]\n",
    "    # Could use the probabilities (instead of [1,0,0] use [0.2,0.55,0.25]\n",
    "\n",
    "yaml_path = path_adjust + \"yaml/preprocessing.yaml\"\n",
    "\n",
    "with open(yaml_path) as file:\n",
    "    yaml_dict = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "config_dictionary = dict(yaml=yaml_path, params=yaml_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "yaml_path = path_adjust + \"yaml/preprocessing.yaml\"\n",
    "\n",
    "with open(yaml_path) as file:\n",
    "    yaml_dict = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "config_dictionary = dict(yaml=yaml_path, params=yaml_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yaml': '../yaml/preprocessing.yaml',\n",
      " 'params': {'window_length': {'desc': 'Length of the input feature window',\n",
      "   'value': 200},\n",
      "  'profit_taking_multiplier': {'desc': 'Vertical Barrier profit taking multiplier',\n",
      "   'value': 1},\n",
      "  'stop_loss_multiplier': {'desc': 'Vertical Barrier profit taking multiplier',\n",
      "   'value': 1},\n",
      "  'minimum_return': {'desc': 'Amount of return chosen to consider it a profitable trade',\n",
      "   'value': '0.001 * 1 / 23'}}}"
     ]
    }
   ],
   "source": [
    "config_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dictionary.params.minimum_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yaml': '../yaml/preprocessing.yaml',\n",
      " 'params': {'window_length': {'desc': 'Length of the input feature window',\n",
      "   'value': 200},\n",
      "  'profit_taking_multiplier': {'desc': 'Vertical Barrier profit taking multiplier',\n",
      "   'value': 1},\n",
      "  'stop_loss_multiplier': {'desc': 'Vertical Barrier profit taking multiplier',\n",
      "   'value': 1},\n",
      "  'minimum_return': {'desc': 'Amount of return chosen to consider it a profitable trade',\n",
      "   'value': '0.001 * 1 / 23'}}}"
     ]
    }
   ],
   "source": [
    "config_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'desc': 'Amount of return chosen to consider it a profitable trade',\n",
      " 'value': '0.001 * 1 / 23'}"
     ]
    }
   ],
   "source": [
    "config_dictionary['params']['minimum_return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dictionary['params']['minimum_return'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    dir=\"~/ProdigyAI/\",\n",
    "    project=\"prodigyai\",\n",
    "    config=config_dictionary,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B Run: https://app.wandb.ai/garthtrickett/prodigyai/runs/2mak5z83"
     ]
    }
   ],
   "source": [
    "wandb.init(\n",
    "    dir=\"~/ProdigyAI/\",\n",
    "    project=\"prodigyai\",\n",
    "    config=config_dictionary,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
